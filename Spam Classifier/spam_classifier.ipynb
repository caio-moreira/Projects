{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n",
    "\n",
    "This dataset can be found on\n",
    "https://www.kaggle.com/uciml/sms-spam-collection-dataset/downloads/sms-spam-collection-dataset.zip/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('data.csv', encoding='latin-1')\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Body\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   ham        u dun say so early hor u c already then say\n",
       "4   ham  nah i dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame\n",
    "data = raw_data.copy()\n",
    "\n",
    "# Selecting only the columns that will be used\n",
    "data = data[['v1', 'v2']]\n",
    "\n",
    "# Renaming the columns\n",
    "data.columns = ['Class', 'Body']\n",
    "\n",
    "# Lowering chars in every row of the Body column\n",
    "data['Body'] = data['Body'].str.lower()\n",
    "\n",
    "# Replacing latin-1 special characters with regular characters\n",
    "data['Body'] = data['Body'].replace(regex={\n",
    "    r'[áàâäã]': 'a', r'[éèêë]': 'e',\n",
    "    r'[íìîï]': 'i', r'[óòôöõ]': 'o',\n",
    "    r'[úùûü]': 'u', 'ç': 'c'\n",
    "})\n",
    "\n",
    "# Replacing special characters with a whitespace\n",
    "# Note that this can cause a repetiton of whitespaces, that is going to be handled below\n",
    "data['Body'] = data['Body'].replace(to_replace='[\\n|\\t|\\r]', value=' ', regex=True)\n",
    "\n",
    "# Replacing anything that is not a letter, a whitespace, a digit or any scape character\n",
    "data['Body'] = data['Body'].replace(to_replace='[^a-z 0-9]', value='', regex=True)\n",
    "\n",
    "# Handling multiple whitespaces problem\n",
    "data['Body'] = data['Body'].replace(to_replace='( )+', value=' ', regex=True)\n",
    "\n",
    "# Trimming whitespaces\n",
    "data['Body'] = data['Body'].str.strip()\n",
    "\n",
    "# Showing its shape to see the number of rows and first 5 rows\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Naïve-Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \"\"\" This is a class that defines the Naive-Bayes model.\n",
    "  \n",
    "    Attributes: \n",
    "        labels -- list that stores the possible labels for the model to predict\n",
    "        labels_prob -- pandas DataFrame that will be used to store the overall probability of each label to happen\n",
    "        words_labels_prob -- pandas DataFrame that contains the probability of a label happening given that a word is present\n",
    "        vocabulary -- a set containing all of the known distinct words\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Constructor for the NaiveBayes Class.\n",
    "        \n",
    "        All of the attributes start empty so that they are populated upon calling the fit function.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.labels = []\n",
    "        \n",
    "        self.labels_prob = pd.DataFrame(columns=['Label', 'Probability'])\n",
    "        \n",
    "        self.words_labels_prob = pd.DataFrame(columns=['Label', 'Word', 'Probability'])\n",
    "        \n",
    "        self.vocabulary = set()\n",
    "\n",
    "    def fit(self, train_set, labels=['ham', 'spam']):\n",
    "        \"\"\" Function that fit the model to given data. \n",
    "\n",
    "        Keyword arguments: \n",
    "            train_set -- data to be fitted on\n",
    "            labels -- labels that can be found on the training set (default ['ham', 'spam']) \n",
    "        \"\"\"\n",
    "        # Overwriting the labels variable in case the user has changed from default\n",
    "        self.labels = labels\n",
    "\n",
    "        # Cleaning the class variables so that they will be clean to learn\n",
    "        # If the instance has previously called this function they will have some data\n",
    "        self.labels_prob = pd.DataFrame(columns=['Label', 'Probability'])\n",
    "        self.words_labels_prob = pd.DataFrame(columns=['Label', 'Word', 'Probability'])\n",
    "\n",
    "        # Cleaning and filling the vocabulary, list of all distinct words in the training set\n",
    "        self.vocabulary = set()\n",
    "        self.vocabulary = ' '.join(train_set['Body'].to_list())\n",
    "        self.vocabulary = set(self.vocabulary.split())\n",
    "\n",
    "        # Iterating through each label\n",
    "        for label in labels:\n",
    "            # Creating a list with all the emails wich are classified as the current label\n",
    "            docs = train_set[train_set['Class'] == label].copy()\n",
    "            docs = docs['Body'].to_list()\n",
    "\n",
    "            # Calculating the probability of the answer being the current label\n",
    "            # number of documents labeled as such / total number of documents\n",
    "            prob_label = len(docs) / train_set.shape[0]\n",
    "            \n",
    "            # Appending it into the labels_prob DataFrame\n",
    "            self.labels_prob = self.labels_prob.append({'Label': label, 'Probability': prob_label}, ignore_index=True)\n",
    "\n",
    "            # Creating a list with all the words in the emails in docs(repetitions included)\n",
    "            text = ' '.join(docs)\n",
    "            text = text.split()\n",
    "\n",
    "            # Storing the number of words in the text list\n",
    "            words_in_text = len(text)\n",
    "\n",
    "            # Calculating for each word in the vocabulary the probability of being the current label\n",
    "            # (using vocabulary because it uses only distinct words, so it will run each word only once)\n",
    "            for word in self.vocabulary:\n",
    "                # Getting the number of times the current word shows up in the text\n",
    "                word_occurrences = text.count(word)\n",
    "\n",
    "                # Calculating the probability with the formula\n",
    "                # (number of occurences of the word + 1) / (total number of words + total number of distinct words)\n",
    "                # Standard Naive-Bayes formula using Laplacian smoothing \n",
    "                prob_word_label = (word_occurrences + 1) / (words_in_text + len(self.vocabulary))\n",
    "                \n",
    "                # Appending it into the words_labels_prob DataFrame\n",
    "                self.words_labels_prob = self.words_labels_prob.append({\n",
    "                    'Label': label, 'Word': word, 'Probability': prob_word_label\n",
    "                }, ignore_index=True)\n",
    "    \n",
    "    def predict(self, test):\n",
    "        \"\"\" Function that predicts a label for a given test subject. \n",
    "\n",
    "        Doesn't return the probability of the label (prediction[1]) prediction by choice.\n",
    "\n",
    "        Keyword arguments: \n",
    "            test -- subject to be tested on.  \n",
    "\n",
    "        Returns: \n",
    "            prediction[0] -- the prediction.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Creating a list with all words in the test document\n",
    "        # and filters it for known words\n",
    "        words = test.split()\n",
    "        words = [word for word in words if word in self.vocabulary]\n",
    "        \n",
    "        # Creating prediction variable, which will have the label with the highest probability\n",
    "        # and the probability of the prediction\n",
    "        prediction = ['Label', -1]\n",
    "        \n",
    "        # Calculating probability for each label\n",
    "        for label in self.labels:\n",
    "            # Fetching the probability for the current label in the DataFrame\n",
    "            prob_label = self.labels_prob[self.labels_prob['Label'] == label].reset_index(drop=True)\n",
    "            prob_label = prob_label['Probability'][0]\n",
    "            \n",
    "            # Fetching the probability of being the label for each word in the respective DataFrame\n",
    "            for word in words:\n",
    "                prob_word_label = self.words_labels_prob.query('Label == @label & Word == @word').reset_index(drop=True)\n",
    "                prob_word_label = prob_word_label['Probability'][0]\n",
    "                \n",
    "                # Multiplyting the current probability by the current word_label probability\n",
    "                # The final probability is the multiplication of all the probabilities of label given word and label overall\n",
    "                prob_label *= prob_word_label\n",
    "                \n",
    "            # Replacing the label in the answer variable in case the probability of the current label is higher\n",
    "            if prob_label > prediction[1]:\n",
    "                prediction[0] = label\n",
    "                prediction[1] = prob_label\n",
    "                \n",
    "        return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Body\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   ham        u dun say so early hor u c already then say\n",
       "4   ham  nah i dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining (merging) both DataFrames (full and stop-word filtered) on theirs indexes\n",
    "train_test_data = data.copy()\n",
    "\n",
    "# Showing its shape and first rows to see if Body and Body_Filtered look the same\n",
    "print(train_test_data.shape)\n",
    "train_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-07 21:11:45.164377: Starting.\n",
      "2019-11-07 21:12:18.932912: End of Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1857/1857 [04:05<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-07 21:16:24.626165: Finished.\n",
      "Correct: 1827 out of 1857\n"
     ]
    }
   ],
   "source": [
    "# Storing the number of rows in the dataset\n",
    "data_len = train_test_data.shape[0]\n",
    "\n",
    "# Creating a train set, it has all of the rows in the dataset\n",
    "# The sample method gets a number of rows randomly sorted (sample method), in this case, all rows\n",
    "train = train_test_data.sample(data_len).reset_index(drop=True)\n",
    "\n",
    "# Setting the size of the train set\n",
    "train_size = 2/3\n",
    "\n",
    "test = train[train.index >= data_len * train_size].reset_index(drop=True)\n",
    "train = train[train.index < data_len * train_size]\n",
    "\n",
    "# Printing the start time\n",
    "print(str(datetime.now()) + ': Starting.')\n",
    "\n",
    "# Creating the model instance\n",
    "naivebayes = NaiveBayes()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "naivebayes.fit(train)\n",
    "\n",
    "# Printing the time at the end of the training\n",
    "print(str(datetime.now()) + ': End of Training.')\n",
    "\n",
    "# Creating the list that will store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Predicting and storing the predictions for each subject of the test set\n",
    "for subject in tqdm.tqdm(test['Body']):\n",
    "    predictions.append(naivebayes.predict(subject))\n",
    "\n",
    "# Printing the end time\n",
    "print(str(datetime.now()) + ': Finished.')\n",
    "\n",
    "# Creating a compare DataFrame as a copy of the test one so it will remain intact\n",
    "compare = test.copy()\n",
    "\n",
    "# Adding predictions columns to the compare DataFrame\n",
    "compare['Prediction'] = predictions\n",
    "\n",
    "# Printing the number of correct answers and the number of tests\n",
    "print('Correct:', str(compare[compare['Class'] == compare['Prediction']].shape[0]), 'out of', str(test.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
